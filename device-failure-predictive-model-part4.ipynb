{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Creator: Changhee Kang***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 4 - Developing predictive model with sampling techniques and filter method for variable selection applied**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that:** data manupulation and exploration techniques illustrated in this demonstraton does not mean that the audience have to follow the same ways as shown here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device Failure and Maintenance Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is to build a predictive model with diagnoses of telemetry attributes to classify whether maintenance should be performed on devices or not. The column used for prediction is set with the column name, \"failure\", with binary value 0 for \"non-failure\" and 1 for \"failure\". The goal is to minimize false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there is no meta data that describes the current dataset, assumptions can be applied to the current dataset. The dataset consists of diagnoses of telemetry attributes, so it might be rational that some variables are assumed to consist of *categorical nominal type values* while other variables would consist of *continuous type values*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *'Oversampling'* method will be applied to the current dataset to inflate the number of data point in the minority class. \n",
    "\n",
    "*'Filter Method'* for varialble selection will be applied to choose the best combination for the model preformance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import necessary python modules to load the current dataset into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = r'/home/thomas/Downloads/device_failure.csv'\n",
    "dataset = pd.read_csv(datafile, sep=',', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the predictive model with *'Random Sampling'*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import necessary modules for model developments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from matplotlib.colors import ListedColormap\n",
    "from imblearn import over_sampling\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc, accuracy_score, average_precision_score, precision_recall_curve, roc_auc_score, roc_curve, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a model development procedure. The reason why *'Random Oversampling'* is adopted for a binary classification model should be explained here. Without any sampling techniques, the predictive model did not find any devices with failure, at all. *'Oversampling'* will help increase chances of devices with failure to be selected by *'Random Forest'* algorithm by infalting the number of data points in the minority class to the equal number of data points in the majority class. Thus, the predictive model becomes to learn bot ways to failure and non-failure. One thing to be noted is that *'Oversampling'* is only applied to the training dataset and it is applied inside the cross-validation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Models are built with stratified 10-cross-validation by default. The splitting of data into \n",
    "    folds will ensure that each fold has the same proportion of observations with a given \n",
    "    categorical value, such as the class outcome value. \n",
    "    \n",
    "    This will produce a predictive model according to a set of function parameters such as:\n",
    "    - X: holds independent variables.\n",
    "    - Y: holds the target variable.\n",
    "    - DEPTH: the maximum number of depths each estimator can span.\n",
    "    - NEIGHBORS: the number of neighbors to use for data augmentation.\n",
    "    - ESTIMATORS: the number of estimators.\n",
    "    - WICH_RF: the choice of model development approaches.(no sampling, over-sampling, smote-sampling)\n",
    "        1 - SMOTE.\n",
    "        2 - Random oversampling on minority class.\n",
    "        0 - No sampling techniques applied.\n",
    "    \n",
    "    At the end of the funtion execution, statistical results will be provided on the console.\n",
    "'''\n",
    "def run_model(SUMMARY_TABLE, X, Y, DEPTH, NEIGHBORS, ESTIMATORS, WHICH_MODEL, WHICH_SAMPLING):\n",
    "    predicted = None\n",
    "    \n",
    "    # Convert to dataframe to number to split for cross-valation runs.\n",
    "    numpy_X = X.to_numpy()\n",
    "    numpy_Y = Y.to_numpy()\n",
    "\n",
    "    # Create 10-stratified-folds.\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    rnd_cnt = 1\n",
    "\n",
    "    total_fpr = 0\n",
    "    total_acc = 0\n",
    "    total_err = 0\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1 = 0\n",
    "    total_tp = 0\n",
    "    total_tn = 0\n",
    "    total_train_acc = 0\n",
    "    total_fp = 0\n",
    "    \n",
    "    # Run 10-stratified-cross-validations.\n",
    "    for train_index, test_index in skf.split(numpy_X, numpy_Y):\n",
    "        # Data is numpied.\n",
    "        x_train, x_test = numpy_X[train_index], numpy_X[test_index]\n",
    "        y_train, y_test = numpy_Y[train_index], numpy_Y[test_index]\n",
    "\n",
    "        # convert to dataframe from numpied data.\n",
    "        x_train = pd.DataFrame(x_train.reshape(-1, len(X.columns)),columns=X.columns)    \n",
    "        x_test = pd.DataFrame(x_test.reshape(-1, len(X.columns)),columns=X.columns)\n",
    "        y_train = pd.DataFrame(y_train.reshape(-1, 1))\n",
    "        y_test = pd.DataFrame(y_test.reshape(-1, 1))    \n",
    "        \n",
    "        '''\n",
    "            Do sampling accordingly.\n",
    "        '''\n",
    "        if WHICH_SAMPLING == 'OVER': \n",
    "            # Concatenate y_train to x_train to over-sample\".\n",
    "            train_dataset = x_train\n",
    "            train_dataset['failure'] = y_train\n",
    "\n",
    "            # Split train dataset into true negatives and true positives\n",
    "            train_target_0 = train_dataset[train_dataset.iloc[:,-1] == 0]\n",
    "            train_target_1 = train_dataset[train_dataset.iloc[:,-1] == 1]\n",
    "\n",
    "            #Over-sample data with replacement allowed for the minority class.\n",
    "            train_target_1_oversample = train_target_1.sample(len(train_target_0), replace=True)\n",
    "            train_target_1_oversample.failure.value_counts()\n",
    "            train_oversample = pd.concat([train_target_1_oversample, train_target_0], axis=0)\n",
    "\n",
    "            x_train = train_oversample # Assign over-sampled train dataset to x_train.\n",
    "            y_train = x_train.failure # Copy y values from x_train.\n",
    "            x_train.drop('failure', axis=1, inplace=True) # Drop y values from x_train.\n",
    "        elif WHICH_SAMPLING == 'UNDER':   \n",
    "            # Create random forest classifier with downsampling for the majority class.\n",
    "            x_train_res, y_train_res = RandomUnderSampler(random_state=0).fit_sample(x_train, y_train)\n",
    "            x_train = x_train_res\n",
    "            y_train = y_train_res\n",
    "        else: \n",
    "            pass\n",
    "        \n",
    "        '''\n",
    "            Select and run the model accordingly.\n",
    "        '''\n",
    "        train_acc = 0\n",
    "        \n",
    "        if WHICH_MODEL == 'RF': # Random Forest.\n",
    "            rf = RandomForestClassifier(random_state=0, n_estimators=ESTIMATORS, max_depth=DEPTH)\n",
    "            rf.fit(x_train,y_train) # Fit the model to training dataset.\n",
    "            #predicted = rf.predict(x_test) # Get prediction result.\n",
    "            train_acc = rf.score(x_train, y_train) # train set 정확도\n",
    "            y_pred = rf.predict(x_test)#(rf.predict_proba(x_test)[:,1] >= prob).astype(bool)\n",
    "            \n",
    "        \n",
    "        # Show statistics for each round.\n",
    "        #print(\"Fold - {}\".format(rnd_cnt))\n",
    "        '''\n",
    "            Confusion Matrix\n",
    "        '''\n",
    "        #print(\"-------------  Confusion Matrix  ----------------\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(\"Fold - {}\".format(rnd_cnt))\n",
    "        print(cm)\n",
    "        print()\n",
    "        '''\n",
    "            Get individual counts from confusion matrix for further statistics for \n",
    "            true positive, true negatve, false positive, and false negative.\n",
    "        '''\n",
    "        TN = cm[0][0]\n",
    "        FP = cm[0][1]\n",
    "        FN = cm[1][0]\n",
    "        TP = cm[1][1]\n",
    "        \n",
    "        # Compute totals of true positives and true negatives.\n",
    "        total_tp += TP\n",
    "        total_tn += TN\n",
    "        total_fp += FP\n",
    "        \n",
    "        '''\n",
    "            Statistics for accuray, precision, recall, overall error, and etc..\n",
    "        '''\n",
    "        #print(\"-------------     Statistics     ----------------\")\n",
    "        acc = (TN+TP)/(TN+TP+FN+FP)\n",
    "        precision = TP/(FP+TP)\n",
    "        recall = TP/(FN+TP)\n",
    "        f1 = 2*(precision*recall/(precision+recall))\n",
    "        overall_error = (FP+FN)/(TP+TN+FP+FN)     \n",
    "        fpr = FP/(TN+FP)\n",
    "        \n",
    "        # Compute totals of other statistics.\n",
    "        total_err += overall_error\n",
    "        total_acc += acc\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1 += f1\n",
    "        total_fpr += fpr\n",
    "        total_train_acc += train_acc\n",
    "        \n",
    "        # Increment round by 1.\n",
    "        rnd_cnt += 1\n",
    "    \n",
    "    # Compute averages.\n",
    "    avg_err = round((total_err/10)*100, 2)\n",
    "    avg_acc = round((total_acc/10)*100, 2)\n",
    "    avg_pre = round((total_precision/10)*100, 2)\n",
    "    avg_rec = round((total_recall/10)*100, 2)\n",
    "    avg_f1 = round((total_f1/10)*100, 2)\n",
    "    avg_tp = round((total_tp/10), 2)\n",
    "    avg_tn = round((total_tn/10), 2)\n",
    "    avg_fpr = round((total_fpr/10)*100, 2)\n",
    "    avg_train_acc = round((total_train_acc/10)*100, 2)\n",
    "    avg_fp = round((total_fp/10)*100, 2)\n",
    "\n",
    "    show_classifier_summary(SUMMARY_TABLE, WHICH_MODEL, WHICH_SAMPLING, ESTIMATORS, DEPTH, NEIGHBORS, len(X.columns), avg_train_acc, avg_acc, avg_pre, avg_rec, avg_fpr, avg_err, avg_f1, avg_tp, avg_tn, avg_fp, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a model performance summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_classifier_summary(summary_table, \n",
    "                            which_model, \n",
    "                            which_sample_tech, \n",
    "                            estimators,\n",
    "                            depth,\n",
    "                            neighbor,\n",
    "                            var_len,\n",
    "                            avg_train_acc,\n",
    "                            avg_acc, \n",
    "                            avg_pre, \n",
    "                            avg_rec, \n",
    "                            avg_fpr,\n",
    "                            avg_err, \n",
    "                            avg_f1,\n",
    "                            avg_tp, \n",
    "                            avg_tn, \n",
    "                            avg_fp,\n",
    "                            variables):\n",
    "    \n",
    "    summary_table.append(\n",
    "            [which_model, \n",
    "            which_sample_tech, \n",
    "            estimators,\n",
    "            depth,\n",
    "            neighbor,\n",
    "            var_len,\n",
    "            avg_train_acc,\n",
    "            avg_acc, \n",
    "            avg_pre,\n",
    "            avg_rec,\n",
    "            avg_fpr,\n",
    "            avg_f1,\n",
    "            avg_err, \n",
    "            avg_tp, \n",
    "            avg_tn, \n",
    "            avg_fp,\n",
    "            variables.columns.tolist()]\n",
    "        )\n",
    "    display(HTML(tabulate.tabulate(summary_table, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 1\n",
      "[[11869   570]\n",
      " [    6     5]]\n",
      "\n",
      "Fold - 2\n",
      "[[11902   537]\n",
      " [    2     9]]\n",
      "\n",
      "Fold - 3\n",
      "[[11899   540]\n",
      " [    4     7]]\n",
      "\n",
      "Fold - 4\n",
      "[[12017   422]\n",
      " [    7     4]]\n",
      "\n",
      "Fold - 5\n",
      "[[11963   476]\n",
      " [    4     7]]\n",
      "\n",
      "Fold - 6\n",
      "[[12021   418]\n",
      " [    8     3]]\n",
      "\n",
      "Fold - 7\n",
      "[[12053   386]\n",
      " [    7     3]]\n",
      "\n",
      "Fold - 8\n",
      "[[11993   446]\n",
      " [    6     4]]\n",
      "\n",
      "Fold - 9\n",
      "[[12006   432]\n",
      " [    5     5]]\n",
      "\n",
      "Fold - 10\n",
      "[[11933   505]\n",
      " [    5     5]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>MODEL</td><td>SAMPLING</td><td>ESTIMATORS</td><td>DEPTH</td><td>NEIGHBORS</td><td>VARS</td><td>T_ACC</td><td>ACC. </td><td>PRE.</td><td>REC. </td><td>FPR.</td><td>F1  </td><td>ERR.</td><td>TP </td><td>TN     </td><td>FP     </td><td>VARS.                                                                                                           </td></tr>\n",
       "<tr><td>RF   </td><td>OVER    </td><td>100       </td><td>7    </td><td>0        </td><td>8   </td><td>89.63</td><td>96.16</td><td>1.07</td><td>48.82</td><td>3.8 </td><td>2.09</td><td>3.84</td><td>5.2</td><td>11965.6</td><td>47320.0</td><td>['attribute1', 'attribute2', 'attribute3', 'attribute4', 'attribute5', 'attribute6', 'attribute7', 'attribute9']</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_summary_table = [[\"MODEL\", \"SAMPLING\", \"ESTIMATORS\", \"DEPTH\", \"NEIGHBORS\", \"VARS\", \"T_ACC\", \"ACC.\", \"PRE.\", \"REC.\", \"FPR.\", \"F1\", \"ERR.\", \"TP\", \"TN\", \"FP\", \"VARS.\"]]\n",
    "\n",
    "# Set variables to be participated in the model.\n",
    "X = dataset[['attribute1', 'attribute2', 'attribute3', 'attribute4','attribute5', 'attribute6', 'attribute7', 'attribute9']]\n",
    "Y = dataset.failure\n",
    "DEPTH = 7 # Define the max depth to 7.\n",
    "ESTIMATORS = 100 # Defind the number of decision trees to participate in voting.\n",
    "NEIGHBORS = 0\n",
    "run_model(rf_summary_table, X, Y, DEPTH, NEIGHBORS, ESTIMATORS, 'RF', 'OVER') # 0 for random forest without oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictive model now seems to know ways to failure and non-failure. Although prefereable combinations of variables are not applied, the model with all variables can tell what devices are in failure. Let's try categorical variables only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 1\n",
      "[[11196  1243]\n",
      " [    2     9]]\n",
      "\n",
      "Fold - 2\n",
      "[[11558   881]\n",
      " [    2     9]]\n",
      "\n",
      "Fold - 3\n",
      "[[11501   938]\n",
      " [    4     7]]\n",
      "\n",
      "Fold - 4\n",
      "[[11534   905]\n",
      " [    5     6]]\n",
      "\n",
      "Fold - 5\n",
      "[[11543   896]\n",
      " [    3     8]]\n",
      "\n",
      "Fold - 6\n",
      "[[11595   844]\n",
      " [    4     7]]\n",
      "\n",
      "Fold - 7\n",
      "[[11554   885]\n",
      " [    4     6]]\n",
      "\n",
      "Fold - 8\n",
      "[[11584   855]\n",
      " [    5     5]]\n",
      "\n",
      "Fold - 9\n",
      "[[11635   803]\n",
      " [    3     7]]\n",
      "\n",
      "Fold - 10\n",
      "[[11341  1097]\n",
      " [    4     6]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>MODEL</td><td>SAMPLING</td><td>ESTIMATORS</td><td>DEPTH</td><td>NEIGHBORS</td><td>VARS</td><td>T_ACC</td><td>ACC. </td><td>PRE.</td><td>REC. </td><td>FPR.</td><td>F1  </td><td>ERR.</td><td>TP </td><td>TN     </td><td>FP     </td><td>VARS.                                                                                                           </td></tr>\n",
       "<tr><td>RF   </td><td>OVER    </td><td>100       </td><td>7    </td><td>0        </td><td>8   </td><td>89.63</td><td>96.16</td><td>1.07</td><td>48.82</td><td>3.8 </td><td>2.09</td><td>3.84</td><td>5.2</td><td>11965.6</td><td>47320.0</td><td>['attribute1', 'attribute2', 'attribute3', 'attribute4', 'attribute5', 'attribute6', 'attribute7', 'attribute9']</td></tr>\n",
       "<tr><td>RF   </td><td>OVER    </td><td>100       </td><td>4    </td><td>0        </td><td>5   </td><td>82.04</td><td>92.46</td><td>0.75</td><td>65.82</td><td>7.51</td><td>1.48</td><td>7.54</td><td>7.0</td><td>11504.1</td><td>93470.0</td><td>['attribute3', 'attribute4', 'attribute5', 'attribute7', 'attribute9']                                          </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set variables to be participated in the model.\n",
    "X = dataset[['attribute3', 'attribute4','attribute5', 'attribute7', 'attribute9']]\n",
    "Y = dataset.failure\n",
    "DEPTH = 4 # Define the max depth to 7.\n",
    "ESTIMATORS = 100 # Defind the number of decision trees to participate in voting.\n",
    "NEIGHBORS = 0\n",
    "run_model(rf_summary_table, X, Y, DEPTH, NEIGHBORS, ESTIMATORS, 'RF', 'OVER') # 0 for random forest without oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, try another combination of variables such as *'attribute4'* and *'attribute7'* only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold - 1\n",
      "[[11113  1326]\n",
      " [    2     9]]\n",
      "\n",
      "Fold - 2\n",
      "[[11493   946]\n",
      " [    0    11]]\n",
      "\n",
      "Fold - 3\n",
      "[[11507   932]\n",
      " [    4     7]]\n",
      "\n",
      "Fold - 4\n",
      "[[11516   923]\n",
      " [    5     6]]\n",
      "\n",
      "Fold - 5\n",
      "[[11516   923]\n",
      " [    3     8]]\n",
      "\n",
      "Fold - 6\n",
      "[[11543   896]\n",
      " [    4     7]]\n",
      "\n",
      "Fold - 7\n",
      "[[11535   904]\n",
      " [    3     7]]\n",
      "\n",
      "Fold - 8\n",
      "[[11476   963]\n",
      " [    5     5]]\n",
      "\n",
      "Fold - 9\n",
      "[[11445   993]\n",
      " [    2     8]]\n",
      "\n",
      "Fold - 10\n",
      "[[11197  1241]\n",
      " [    4     6]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>MODEL</td><td>SAMPLING</td><td>ESTIMATORS</td><td>DEPTH</td><td>NEIGHBORS</td><td>VARS</td><td>T_ACC</td><td>ACC. </td><td>PRE.</td><td>REC. </td><td>FPR.</td><td>F1  </td><td>ERR.</td><td>TP </td><td>TN     </td><td>FP      </td><td>VARS.                                                                                                           </td></tr>\n",
       "<tr><td>RF   </td><td>OVER    </td><td>100       </td><td>7    </td><td>0        </td><td>8   </td><td>89.63</td><td>96.16</td><td>1.07</td><td>48.82</td><td>3.8 </td><td>2.09</td><td>3.84</td><td>5.2</td><td>11965.6</td><td>47320.0 </td><td>['attribute1', 'attribute2', 'attribute3', 'attribute4', 'attribute5', 'attribute6', 'attribute7', 'attribute9']</td></tr>\n",
       "<tr><td>RF   </td><td>OVER    </td><td>100       </td><td>4    </td><td>0        </td><td>5   </td><td>82.04</td><td>92.46</td><td>0.75</td><td>65.82</td><td>7.51</td><td>1.48</td><td>7.54</td><td>7.0</td><td>11504.1</td><td>93470.0 </td><td>['attribute3', 'attribute4', 'attribute5', 'attribute7', 'attribute9']                                          </td></tr>\n",
       "<tr><td>RF   </td><td>OVER    </td><td>100       </td><td>2    </td><td>0        </td><td>2   </td><td>80.88</td><td>91.9 </td><td>0.74</td><td>69.64</td><td>8.08</td><td>1.47</td><td>8.1 </td><td>7.4</td><td>11434.1</td><td>100470.0</td><td>['attribute4', 'attribute7']                                                                                    </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set variables to be participated in the model.\n",
    "X = dataset[['attribute4', 'attribute7']]\n",
    "Y = dataset.failure\n",
    "DEPTH = 2 # Define the max depth to 7.\n",
    "ESTIMATORS = 100 # Defind the number of decision trees to participate in voting.\n",
    "NEIGHBORS = 0\n",
    "run_model(rf_summary_table, X, Y, DEPTH, NEIGHBORS, ESTIMATORS, 'RF', 'OVER') # 0 for random forest without oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is, kind of, satisfactory but the model does not know which variables it should use for the best performance. So far, variables are added to the model development manually with heuristic human labors for the best variable selection. The problem that is used in the model development process is that variable importances are calculated with isolation of other variables, which means that each variable's importance score was test for the relationship with only the target variable. It is almost impossible for people to think of the best combination of variables that gives the best model performance because there might be a lot of different combinations of variables. For example, if there are 5 variables in a dataset, there will be $$ 2^5-1 = 32 $$ combinations to test for the best combination of variables. When there are more variables involved in a dataset, then, as said, it will be impossible to imagine how variables will affect the predictive model performance. \n",
    "\n",
    "In the next part, the model development will adopt *'filter method'* and *'wrapper method'* to choose the best variables for the model. With *'filter method'*, each varible will be in isonlation with other variables, it only shows significance towards the target variable. *'Filter method'* are similar to manual variables additions to the model development but it helps automate variables selections for model developments. \n",
    "\n",
    "However, when the relationship between a combination of variables and the target variable, *'filter method'* would not be appropriate to choose the best variables for the model. So *'wrapper method'* will be introduced for the relationship between multi-variables and the target variable using machine learning algorithms to choose the best combination of variables for the prediction performance. *'Filter method'* is introduced in *'part 4'* and *'Wrapper Method'* is introduced in *'part 5'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws-test4",
   "language": "python",
   "name": "aws-test4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
